<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: programming | Rahul Nath]]></title>
  <link href="http://rahulpnath.com/blog/category/programming/atom.xml" rel="self"/>
  <link href="http://rahulpnath.com/"/>
  <updated>2018-01-11T00:01:29+00:00</updated>
  <id>http://rahulpnath.com/</id>
  <author>
    <name><![CDATA[Rahul Nath]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Setting up Build and Deploy Pipeline for a .NET Core Console Application]]></title>
    <link href="http://rahulpnath.com/blog/build-and-deploy-a-net-core-console-application/"/>
    <updated>2018-01-03T00:00:00+00:00</updated>
    <id>http://rahulpnath.com/blog/build-and-deploy-a-net-core-console-application</id>
    <content type="html"><![CDATA[<p>I was given a console application written in .NET Core 2.0 and asked to set up a continuous deployment pipeline using <a href="https://www.jetbrains.com/teamcity/">TeamCity</a> and <a href="https://octopus.com/">Octopus Deploy</a>. I struggled a bit with some parts, so thought it&rsquo;s worth putting together a post on how I went about it. If you have a better or different way of doing things, please shout out in the comments below.</p>

<p>At the end of this post, we will have a console application that is automatically deployed to a server and running, anytime a change is pushed to the associated source control repository.</p>

<h3>Setting Up TeamCity</h3>

<p>Create a <a href="https://confluence.jetbrains.com/display/TCD10/Creating+and+Editing+Projects">New Project</a> and add a <a href="https://confluence.jetbrains.com/display/TCD10/Creating+and+Editing+Build+Configurations">new build configuration</a> just like you would for any other project. Since the application is in .NET Core, install the <a href="https://github.com/JetBrains/teamcity-dotnet-plugin">.NET CLI plugin</a> on the TeamCity server.</p>

<p><img src="/images/net_core_teamcity_build_steps.png" alt="Build Steps to build .Net Core"></p>

<p>The first three build steps use the .NET CLI to <a href="https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-restore?tabs=netcore2x">Restore</a>, <a href="https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-build?tabs=netcore2x">Build</a> and <a href="https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-publish?tabs=netcore2x">Publish</a> the application. Thee three steps restore the dependencies of the project, builds it and publishes all the relevant DLL&rsquo;s into the publish folder.</p>

<p>The published application now needs to be packaged for deployment. In my case, deployments are managed using Octopus Deploy. For .NET projects, the preferred way of packaging for Octopus is using <a href="https://octopus.com/docs/packaging-applications/creating-packages/nuget-packages/using-octopack">Octopack</a>. However, OctoPack does not support .NET Core projects. The recommendation is to either use <a href="https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-pack?tabs=netcore2x">dotnet pack</a> or <a href="https://octopus.com/docs/packaging-applications/creating-packages/nuget-packages/using-octo.exe">Octo.exe pack</a>. Using the latter I have set up a Command Line build step to pack the contents of the published folder into a zip (.nupkg) file.</p>

<pre><code class="bash">octo pack --id ApplicationName --version %build.number% --basePath published-app 
</code></pre>

<p>The NuGet package is published to the NuGet server used by Octopus. Using the <a href="https://octopus.com/docs/api-and-integration/teamcity">Octopus Deploy: Create Release</a> build step, a new release is triggered in Octopus Deploy.</p>

<h3>Setting Up Octopus Deploy</h3>

<p>Create a <a href="https://octopus.com/docs/deployment-process/projects">new project</a> in Octopus Deploy to manage deployments. Under the Process tab, I have two <a href="https://octopus.com/docs/deployment-process/steps">steps</a> - one to deploy the Package and another to start the application.</p>

<p><img src="/images/net_core_octopus_deploy_process.png" alt="Octopus Deploy Process Steps"></p>

<p>For the Deploy Package step I have enabled Custom Deployment Scripts and <a href="https://octopus.com/docs/deploying-applications/deploying-asp.net-core-web-applications/json-configuration-variables-feature">JSON Configuration variables</a>. Under the pre-deployment script, I stop any existing .NET applications. If multiple .NET applications are running on the box, select your application explicitly.</p>

<pre><code class="powershell Pre Deployment Script">Stop-Process -Name dotnet -Force -ErrorAction SilentlyContinue
</code></pre>

<p>Once the package is deployed, the custom script starts up the application.</p>

<pre><code class="powershell Run App">cd C:\DeploymentFolder
Start-Process dotnet .\ApplicationName.dll
</code></pre>

<p>With all that set, any time a change is pushed into the source control repository, TeamCity picks that up, build and triggers a deployment to the configured environments in Octopus Deploy. Hope this helps!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scheduling Recurring Jobs With a Cool-Off Period]]></title>
    <link href="http://rahulpnath.com/blog/scheduling-recurring-jobs-with-a-cool-off-period/"/>
    <updated>2017-12-24T00:00:00+00:00</updated>
    <id>http://rahulpnath.com/blog/scheduling-recurring-jobs-with-a-cool-off-period</id>
    <content type="html"><![CDATA[<p><a href="https://flic.kr/p/8ys6Hs" class="center" ><img class="center" alt="Scheduling" src="/images\scheduling_jobs.jpg" /></a></p>

<p>At one of my clients, they had a requirement of scheduling various rules to sent our alert messages via SMS, Email, etc. A Rule consists of below and a few other properties</p>

<ul>
<li><strong>Stored Procedure</strong>: The Stored Procedure (yes you read it correctly) to check if an alert needs to be raised</li>
<li><strong>Polling Interval</strong>: The time interval in which a Rule needs to be checked.</li>
<li><strong>Cool-Off Period</strong>: Time to wait before running Rule again after an alert was raised.</li>
</ul>


<p>All Rules are stored in a database. New rules can be added and existing ones updated via an external application. Since the client is not yet in the Cloud, using any of Azure Functions, Lambda, Web Jobs, etc. are out of the question. It needs to be a service running on-premise, so I decided to keep it as a Windows service.</p>

<pre><code class="csharp"> public class Rule
{
    public int Id { get; set; }
    public string Name { get; set; }
    public string StoredProc { get; set; }
    public TimeSpan PollingInterval { get; set; }
    public TimeSpan CoolOffPeriod { get; set; }
    ...
}
</code></pre>

<p>Because of my past good experiences with <a href="https://www.hangfire.io/">HangFire</a> I initially set off using that only to discover soon that it can schedule jobs only to the minute level. Even though this is a <a href="https://github.com/HangfireIO/Hangfire/issues/167">feature that has been discussed for a long time</a>, it&rsquo;s yet to be implemented. Since some of the rules are critical to the business, they want to be notified as soon as possible. This means having a polling interval in seconds for those rules.</p>

<p>After reaching out to my <a href="http://www.rahulpnath.com/blog/finding-a-job-abroad/">friends at Readify</a>, I decided to use <a href="https://www.quartz-scheduler.net/">Quartz.net</a>. Many had good experiences using it in the past and recommended it highly. One another option that came up was <a href="https://github.com/fluentscheduler/FluentScheduler">FluentScheduler</a>. There was no particular reason to go with Quartz.net.</p>

<blockquote><p><em>Quartz.NET is a full-featured, open source job scheduling system that can be used from smallest apps to large-scale enterprise systems.</em></p></blockquote>

<p>Setting up and getting started with Quartz scheduler is fast and easy. The library has a <a href="https://www.quartz-scheduler.net/documentation/index.html">well-written documentation</a>. You can update the applications configuration file to tweak various attributes of the scheduler.</p>

<pre><code class="xml App/Web.config file">&lt;configuration&gt;
  &lt;configSections&gt;
    &lt;section name="quartz" type="System.Configuration.NameValueSectionHandler, System, Version=1.0.5000.0,Culture=neutral, PublicKeyToken=b77a5c561934e089" /&gt;
  &lt;/configSections&gt;
  &lt;quartz&gt;
    &lt;add key="quartz.scheduler.instanceName" value="TestScheduler" /&gt;
    &lt;add key="quartz.jobStore.type" value="Quartz.Simpl.RAMJobStore, Quartz" /&gt;
  &lt;/quartz&gt;
&lt;/configuration&gt;
</code></pre>

<p>The <a href="http://www.quartz-scheduler.org/api/2.2.1/org/quartz/simpl/RAMJobStore.html">RAMJobStore</a> indicates the store to use for storing job. There are other job stores available if you want persistence of jobs anytime the application restarts.</p>

<h3>Setting Up Jobs</h3>

<p>Basically, there are three jobs - Alert Job, CoolOff Job, and Refresh Job - set up for the whole application. The Alert and Refresh Jobs are scheduled on application start. The CoolOff Job is triggered by the Alert Job as required. Any data that is required by the job is passed in using <a href="https://www.quartz-scheduler.net/documentation/quartz-2.x/tutorial/more-about-jobs.html#jobdatamap">JobDataMap</a>.</p>

<pre><code class="csharp Schedule an Alert Job">...
var job = JobBuilder.Create&lt;AlertJob&gt;()
    .WithIdentity(rule.GetJobKey())
    .WithDescription(rule.Name)
    .SetJobData(rule)
    .Build();

var trigger = TriggerBuilder
    .Create()
    .WithIdentity(rule.GetTriggerKey())
    .StartNow()
    .WithSimpleSchedule(a =&gt; a
        .WithIntervalInSeconds((int)rule.PollingInterval.TotalSeconds)
        .RepeatForever())
    .Build();

scheduler.ScheduleJob(job, trigger);
</code></pre>

<h4><strong>Alert Jobs</strong></h4>

<p>The Alert Job is responsible for checking the stored procedure and sending the alerts if required. If an alert is sent, it starts the CoolOff Job and pauses the current job instance. THe DisallowConcurrentExecution prevents multiple instances of the Job having the same key does not execute concurrently. We explicitly set the Job Key based on the Rule Id. This prevents any duplicate messages getting sent out if any of the job instances takes more time to execute than its set polling interval.</p>

<pre><code class="csharp">[DisallowConcurrentExecution]
public class AlertJob : Job
{
    public void Execute(IJobExecutionContext context)
    {
        var alert = context.GetRuleFromJobData();
        var message = GetAlertMessage(alert);
        if(message != null)
        {
            SendMessage(message);
            CoolOff(alert);
        }    
    }

    public void CoolOff(Rule rule)
    {
        var job = JobBuilder.Create&lt;CoolOffJob&gt;()
            .WithIdentity(jobKey)
            .WithDescription(rule.MessageTitle)
            .SetJobData(rule)
            .Build();

        var trigger = TriggerBuilder
            .Create()
            .WithIdentity(rule.GetCoolOffTriggerKey())
            .StartAt(rule.GetCoolOffDateTimeOffset())
            .Build();

        scheduler.PauseJob(rule.GetJobKey());
        scheduler.ScheduleJob(job, trigger);
    }
    ...
}
</code></pre>

<h4><strong>Cool-Off Job</strong></h4>

<p>Cool-Off Jobs is a one time job scheduled by the Alert Job after an alert is sent successfully. The CoolOff job is scheduled to start after the Cool-Off time as configured for the alert. This triggers the job only after the set amount of time. It Resumes the original Rule Job to continue execution.</p>

<pre><code class="csharp">public class CoolOffJob : IJob
{
    public void Execute(IJobExecutionContext context)
    {
        var alert = context.GetRuleFromJobData();
        ScheduleHelper.ResumeJob(alert);
    }
}
</code></pre>

<h4><strong>Refresh Job</strong></h4>

<p>The Refresh Job is a recurring job, that polls the database for any changes to the Rules themselves If any change is detected,it removes the existing schedules for the alert and adds the updated alert job.</p>

<pre><code class="csharp">[DisallowConcurrentExecution]
public class RefreshJob : IJob
{
    public void Execute(IJobExecutionContext context)
    {
        var allRules = GetAllRules();
        ScheduleHelper.RefreshRules(allRules);
    }
}
</code></pre>

<p>With these three jobs, all the rules get scheduled at the start of the application and run continuously. Anytime a change is made to the rule itself, the Refresh Job refreshes it within the time interval that it is scheduled for.</p>

<div class="alert alert-info">
<b>Tip:</b>If there are a lot of rules with the same polling interval it will be good to stagger their starting time using a delayed start per job instance. Doing that will make sure that all jobs do not get polled for at the same time.
</div>


<p>So far I have found the Quartz library stable and reliable and have not faced any issues with it. The library is also quite flexible and adapts well to the different needs.</p>

<p>Hope this helps. Merry Xmas!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Generating a Large PDF from Website Contents - Merging PDF Files]]></title>
    <link href="http://rahulpnath.com/blog/generating-a-large-pdf-from-website-contents-part-iii/"/>
    <updated>2017-09-19T00:00:00+00:00</updated>
    <id>http://rahulpnath.com/blog/generating-a-large-pdf-from-website-contents-part-iii</id>
    <content type="html"><![CDATA[<p>In the previous post, <a href="http://www.rahulpnath.com/blog/generating-a-large-pdf-from-website-contents-part-ii/">Generating a Large PDF from Website Contents - HTML to PDF, Bookmarks and Handling Empty Pages</a>, we saw how to generate a PDF from HTML and add bookmarks to the generated PDF files. The PDF file generated is for an individual section which now needs to be merged to form a single PDF file. The individual PDF files contain the relevant content for the section and related bookmarks, which needs to be combined into a single PDF file.</p>

<p>One of the important things to keep intact when merging is the document hierarchy. The Sections, Sub-Categories, and Categories should align correctly so that the final bookmark tree and the Table of Contents appear correctly. It is best to maintain the list of individual PDF document streams in the same hierarchy as required. Since we know the required structure right from the UI, this can be easily achieved by using a data structure similar as shown below</p>

<pre><code class="csharp">public class DocumentSection
{
    public MemoryStream PDFDocument {get; set;}

    public List&lt;DocumentSection&gt; ChildSections {get; set;}

    ... // Any additional details that you need
}
</code></pre>

<p>The above structure allows us to maintain a tree-like structure of the document. The structure is the same as that is provided to the user to select the PDF options. I used the <a href="https://www.nuget.org/packages/iTextSharp-LGPL/">iTextSharp</a> library to merge PDF documents. To interact with the PDF, we first need to create a PdfReader object from the stream. Using the  SimpleBookmark class, we can get the existing bookmarks for the PDF.</p>

<pre><code class="csharp">var pdfReader = new PdfReader(stream);
ArrayList bookmarks = SimpleBookmark.GetBookmark(pdfReader);
</code></pre>

<p>iText representation of bookmarks is a bit complex. It represents them as an ArrayList of Hashtables. The Hashtable has keys like Action, Title, Page, Kids, etc. Kids property represents child bookmarks and is the same ArrayList type. Since it was hard to work with this structure, I created a wrapper class to interact easily with the bookmarks.</p>

<pre><code class="csharp">public class Bookmark
{
    public Bookmark(
        string title, string destinationType, int pageNumber, 
        float xLeft, float yTop, float zZoom)
    {
        Children = new List&lt;Bookmark&gt;();
        Title = title;
        PageNumber = pageNumber;
        DestinationType = destinationType ?? "XYZ";
        XLeft = xLeft;
        YTop = yTop;
        ZZoom = zZoom;
        PageBreak = false;
    }

    ... // Class properties for the constructor parameters

    public ArrayList ToiTextBookmark()
    {
        ArrayList arrayList = new ArrayList
        {
            ToiTextBookmark(this),
        };
        return arrayList;
    }

    private Hashtable ToiTextBookmark(Bookmark bookmark)
    {
        var kids = new ArrayList();
        var hashTable = new Hashtable
        {
            ["Action"] = "GoTo",
            ["Title"] = bookmark.Title,
            ["Page"] = $@"{bookmark.PageNumber} {bookmark.DestinationType} 
                         {bookmark.XLeft} {bookmark.YTop} {bookmark.ZZoom}",
            ["Kids"] = kids,
        };

        foreach (var childBookmark in bookmark.Children)
        {
            kids.Add(ToiTextBookmark(childBookmark));
        }

        return hashTable;
    }
}
</code></pre>

<p>Recursively iterating through the list of DocumentSections, I add all the bookmarks to a root Bookmark class. The root bookmark class represents the full bookmark of the PDF file. The PageNumber is offset using a counter variable. The counter variable is incremented by the number of pages in each of PDF section (<em>pdfReader.NumberOfPages</em>) as it gets merged to the bookmark root. This ensures that the bookmark points to the correct bookmark page in the combined PDF file.</p>

<p>The individual documents are then merged by iterating through all the generated document sections. Once done we get the final PDF as a byte array which is returned to the user.</p>

<pre><code class="csharp">public byte[] MergeSections(List&lt;DocumentSection&gt; documentSections, Bookmark bookmarkRoot)
{
    int pageNumber = 0;
    using (var stream = new MemoryStream())
    {
        var document = new Document();
        var pdfWriter = PdfWriter.GetInstance(document, stream);
        document.Open();
        var pdfContent = pdfWriter.DirectContent;
        MergeSectionIntoDocument(documentSections, document, pdfContent, pdfWriter, pageNumber);
        pdfWriter.Outlines = bookmarkRoot.ToiTextBookmark();
        document.Close();
        stream.Flush();
        return stream.ToArray();
    }
}

private void MergeSectionIntoDocument(
    List&lt;DocumentSection&gt; documentSections,
    Document document,
    PdfContentByte pdfContent,
    PdfWriter pdfWriter,
    int pageNumber)
{
    foreach (var documentSection in documentSections)
    {
        var stream = documentSection.DocumentStream;
        stream.Position = 0;
        var pdfReader = new PdfReader(stream);

        for (var i = 1; i &lt;= pdfReader.NumberOfPages; i++)
        {
            var page = pdfWriter.GetImportedPage(pdfReader, i);
            document.SetPageSize(new iTextSharp.text.Rectangle(0.0F, 0.0F, page.Width, page.Height));
            document.NewPage();
            pageNumber++;
            pdfContent.AddTemplate(page, 0, 0);
            this.AddPageNumber(pdfContent, document, pageNumber);
        }

        if(documentSection.ChildSections.Any())
            MergeSectionIntoDocument(documentSection.ChildSections, document, pdfContent, pdfWriter, pageNumber);
    }
}
</code></pre>

<p>To generate a Table of Contents (ToC), we can use the root bookmark information. We need to manually create a PDF page, read the bookmark text and add links to the page with the required font and styling. iText provides API&rsquo;s to create custom PDF pages.</p>

<p>We are now able to generate a single PDF based on the website contents.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NDC Sydney 2017]]></title>
    <link href="http://rahulpnath.com/blog/ndc-sydney-2017/"/>
    <updated>2017-08-21T00:00:00+00:00</updated>
    <id>http://rahulpnath.com/blog/ndc-sydney-2017</id>
    <content type="html"><![CDATA[<p>Last week was a busy one at <a href="http://ndcsydney.com/">NDC Sydney</a> and was happy to be back there <a href="http://www.rahulpnath.com/blog/ndc-sydney/">for the second time</a>.The conference was three days long with 117 speakers, 37 technologies, and 151 talks. Some of the popular speakers were <a href="https://fsharpforfunandprofit.com/">Scott Wlaschin</a>, <a href="http://odetocode.com/about/scott-allen">Scott Allen</a>,<a href="https://www.troyhunt.com/">Troy Hunt</a>, <a href="https://twitter.com/DamianEdwards">Damian Edwards</a>, <a href="http://blog.stevensanderson.com/">Steve Sanderson</a> and <a href="http://ndcsydney.com/speakers/">a lot more</a>.</p>

<p><img class="center" alt="NDC Sydney" src="/images/ndc_sydney_2017.png" /></p>

<h3>Sessions</h3>

<p>Each talk is one hour long and <a href="http://ndcsydney.com/agenda/">eight talks happen at the same time</a>. Below are the talks I attended:</p>

<ul>
<li><a href="http://ndcsydney.com/talk/keynote-using-eeg-and-machine-learning-to-perform-lie-detection/">Keynote: Using EEG and Machine Learning to Perform Lie Detection</a></li>
<li><a href="http://ndcsydney.com/talk/a-teams-transition-to-continuous-delivery-1/">A teams transition to Continuous Delivery</a></li>
<li><a href="http://ndcsydney.com/talk/docker-from-scratch/">Docker, FROM scratch</a></li>
<li><a href="http://ndcsydney.com/talk/technical-debt/">The Technical Debt Prevention Clinic</a></li>
<li><a href="http://ndcsydney.com/talk/how-to-start-and-run-a-software-lifestyle-business/">How to start and run a software lifestyle business</a></li>
<li><a href="http://ndcsydney.com/talk/asynchronous-programming-from-the-ground-up/">Asynchronous Programming From The Ground Up</a></li>
<li><a href="http://ndcsydney.com/talk/building-docker-applications-with-net-tooling-cross-platform-support-and-migration/">Building Docker Applications with .NET - tooling, cross platform support and migration</a></li>
<li><a href="http://ndcsydney.com/talk/hack_your_career/">Hack Your Career</a></li>
<li><a href="http://ndcsydney.com/talk/writing-high-performance-code-in-net/">Writing high performance code in .NET</a></li>
<li><a href="http://ndcsydney.com/talk/growing-serverless-code-with-azure-functions-and-f/">Growing Serverless code with Azure Functions and F#</a></li>
<li><a href="http://ndcsydney.com/talk/the-websites-down-stories-and-lessons-on-keeping-your-website-up/">&ldquo;The website&rsquo;s down!&rdquo; Stories and lessons on keeping your website up</a></li>
<li><a href="http://ndcsydney.com/talk/self-aware-applications-automatic-production-monitoring/">Self-Aware Applications: Automatic Production Monitoring</a></li>
<li><a href="http://ndcsydney.com/talk/domain-modeling-made-functional/">Domain Modeling Made Functional</a></li>
<li><a href="http://ndcsydney.com/talk/interactive-c-development-with-roslyn/">Interactive C# Development with Roslyn</a></li>
<li><a href="http://ndcsydney.com/talk/building-resilient-applications-in-microsoft-azure/">Building Resilient Applications In Microsoft Azure</a></li>
<li><a href="http://ndcsydney.com/talk/functional-design-patterns/">Functional Design Patterns</a></li>
<li><a href="http://ndcsydney.com/talk/logic-vs-side-effects-functional-goodness-you-dont-hear-about/">Logic vs. side effects: functional goodness you don&rsquo;t hear about</a></li>
<li><a href="http://ndcsydney.com/talk/how-one-team-built-their-first-microservice/">How one team built their first microservice</a></li>
</ul>


<p>All sessions are recorded and are <a href="https://vimeo.com/ndcconferences">available here</a>. The Sydney 2017 ones will soon be there. Overall it was a good event but did not match the one last year. Last year there were more of the popular speakers and the talk content was also more interesting. But still, I am glad that NDC Sydney is still happening, and it gives a good exposure and networking possibilities for developers. Thanks to Readify for sponsoring my tickets and itâ€™s one of the <a href="http://www.rahulpnath.com/blog/finding-a-job-abroad/">good things about working with Readify</a>.</p>

<p>Hope to see you next year as well!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Generating a Large PDF from Website Contents - HTML to PDF, Bookmarks and Handling Empty Pages]]></title>
    <link href="http://rahulpnath.com/blog/generating-a-large-pdf-from-website-contents-part-ii/"/>
    <updated>2017-08-16T00:00:00+00:00</updated>
    <id>http://rahulpnath.com/blog/generating-a-large-pdf-from-website-contents-part-ii</id>
    <content type="html"><![CDATA[<p>In the previous post, <a href="/blog/generating-a-large-pdf-from-website-contents">Generating a Large PDF from Website Contents</a> we saw from a high level the approach taken to generate PDF files from a Content Management System (CMS) website. In this post, we will delve further into the details of each of those areas.</p>

<h3>HTML To PDF</h3>

<p>There are a lot of libraries and services that support converting HTML to PDF. We chose this mechanism mainly for keeping the content formatting simple and reusable. Most of the PDF data was to be structured like the website content. This means we can reuse (read copy/paste) the HTML styling for the PDF content as well.</p>

<p>We used <a href="https://www.essentialobjects.com/Products/EOPdf/Default.aspx">Essential Objects HTML to PDF Converter</a> library. Our website is hosted as an Azure Web App and the <a href="https://www.essentialobjects.com/doc/pdf/install/deploy.aspx">Essential Objects library does not work in the Azure sandbox environment</a>. The <a href="https://github.com/projectkudu/kudu/wiki/Azure-Web-App-sandbox#pdf-generation-from-html">Azure Sandbox restriction</a> affects most of the HTML to PDF libraries. The recommended approach to use those libraries is to host the PDF conversion logic on an Azure Virtual Machine, which is what we also ended up doing. Alternatively, you can choose to use one of the <a href="https://stackoverflow.com/questions/5344176/is-there-a-web-service-for-converting-html-to-pdf">HTML to PDF hosted services</a>.</p>

<p>The below code snippet is what you need to convert an HTML URL endpoint to PDF. It uses the HtmlToPdf class from the <a href="https://www.nuget.org/packages/EO.Pdf/">EO.Pdf Nuget package</a>. The HtmlToPdfOptions specifies various conversion and formatting options. You can set margin space, common headers, footers, etc. for the generated PDF content. It also provides extensibility points in the PDF conversion pipeline.</p>

<pre><code class="csharp">public FileContentResult Convert(string url)
{
    var pdfStream = new MemoryStream();
    var pdfDocument = new PdfDocument();
    var pdfOptions = this.GetPdfOptions();

    var result = HtmlToPdf.ConvertUrl(url, pdfDocument, pdfOptions);
    pdfDocument.Save(pdfStream);

    return new FileContentResult(pdfStream.ToArray(), "application/pdf");
}
</code></pre>

<blockquote><p><strong><em>HTML Formatting Tip</em></strong></p>

<p><em>You might want to avoid content being split across multiple pages. E.g., images, charts, etc. In this cases, you can use the <a href="https://css-tricks.com/almanac/properties/p/page-break/">page-break-*</a> CSS property to adjust page breaks. <a href="https://www.essentialobjects.com/doc/pdf/htmltopdf/paging.aspx">Essentials objects honors the page-break-*</a> settings and adjusts the content when converting into PDF.</em></p></blockquote>

<h3>Bookmarks</h3>

<p><em>A <a href="https://helpx.adobe.com/acrobat/using/page-thumbnails-bookmarks-pdfs.html#about_bookmarks">bookmark</a> is a type of link with representative text in the Bookmarks panel in the navigation pane. Each bookmark goes to a different view or page in the document. Bookmarks are generated automatically during PDF creation from the table-of-contents entries of a document.</em></p>

<p>We generate a lot of small PDF files (per section and category/sub-category) and then merge them together to form the larger PDF. Each of the sections has one or more entries towards Table Of Contents (TOC). We decided to generate bookmarks first per each generated PDF. When merging the individual PDF, the bookmarks are merged first, and then the TOC is created from the full bookmark tree.</p>

<p>Bookmarks can be created automatically or manually using Essential Objects library. Most of the other libraries also provide similar functionality. Using the <a href="https://www.essentialobjects.com/doc/EO.Pdf.HtmlToPdfOptions.AutoBookmark.html">AutoBookmark property</a> we can have bookmarks created automatically based on HTML header (H1-H6) elements. If this does not fit with your scenario, then you can create them manually. In our case, we insert hidden HTML tags to specify bookmarks. Bookmark hierarchy is represented using custom attributes as shown below.</p>

<pre><code class="html">&lt;a class="bookmark" id="TOC_Category1" name="Category1"&gt;Category 1&lt;/a&gt;
...
&lt;a class="bookmark" id="TOC_Category1_Section1" name="Section1" tocParent="TOC_Category1"&gt;Section 1&lt;/a&gt;
...
&lt;a class="bookmark" id="TOC_Category1_Section2" name="Section2" tocParent="TOC_Category1"&gt;Section 2&lt;/a&gt;
...
</code></pre>

<p>Once the PDF is created from the URL, we parse the HTML content for elements with <em>bookmark</em> class and manually add the bookmarks into the generated PDF. The <em><a href="https://www.essentialobjects.com/doc/EO.Pdf.HtmlDocument.GetElementsByClassName_overload_1.html">GetElementsByClassName</a></em> and the <em><a href="https://www.essentialobjects.com/doc/EO.Pdf.HtmlElement.CreateBookmark_overloads.html">CreateBookmark</a></em> methods help us to create bookmarks from the hidden HTML elements in the page.</p>

<pre><code class="csharp">{
 ...
 var result = HtmlToPdf.ConvertUrl(url, pdfDocument, pdfOptions);
 BuildBookmarkTree(pdfDocument, result);
 pdfDocument.Save(pdfStream);
 ...
}

private static void BuildBookmarkTree(PdfDocument pdfDocument, HtmlToPdfResult htmlToPdfResult)
{
    var bookmarkElements = htmlToPdfResult.HtmlDocument.GetElementsByClassName("bookmark");
    foreach (var htmlElement in bookmarkElements)
    {
        var bookmark = htmlElement.CreateBookmark();
        ... // Custom logic to build the bookmark hierarchy
        // based on custom attributes or whatever approach you choose.

        pdfDocument.Bookmarks.Add(bookmark);
    }
}
</code></pre>

<h3>Handling Empty Pages</h3>

<p>In our case, the content is from a CMS, and the user gets an option to select what categories/sub-categories and sections of data to be displayed in the generated PDF. At times it happens that some of the selected combinations might not have any data in the system. To avoid printing a blank page (or an error page) in the generated PDF, we can check the conversion result to check for the returned content. Whenever the content does not exists the HTML endpoint returns an <a href="https://msdn.microsoft.com/en-us/library/system.web.mvc.emptyresult(v=vs.118">EmptyResult class</a>.aspx). At the PDF conversion side, you can check if the response is empty and accordingly perform your logic to ignore the generated PDF.</p>

<pre><code class="csharp">public static class HtmlToPdfResultExtensions
{
    public static bool IsEmptyResponse(this HtmlToPdfResult htmlToPdfResult)
    {
        return htmlToPdfResult != null &amp;&amp;
            htmlToPdfResult.HtmlDocument != null &amp;&amp;
            htmlToPdfResult.HtmlDocument.Body != null &amp;&amp;
            string.IsNullOrEmpty(htmlToPdfResult.HtmlDocument.Body.InnerText);
    }
}
</code></pre>

<p>Once the individual PDF files are created for each of the section and category/subcategory combination, we can merge them together to generate the full PDF. We will see in the next post how to merge the bookmarks together along with shifting the PDF pages and generating Table of Contents from the bookmarks.</p>
]]></content>
  </entry>
  
</feed>
